Машинное обучение "без учителя". Задача кластеризации.
Работу выполнила: Бобина Татьяна Сергеевна ПМИ3-1
В практических примерах ниже показано:

как пользоваться инструментами визуального анализа для предварительной интерпретации кластеров
как проводить кластерный анализ
как строить прогноз принадлежности к кластерам новых наблюдений
как оценивать точность кластеризации
Модели: иерархический и неиерархический кластерный анализ

Данные: load_iris

Данные в примере:

sepal length (cm) - длина чашелистика (см)
sepal width (cm) - ширина чашелистика (см)
petal length (cm) - длина лепестка (см)
petal width (cm) - ширина лепестка (см)
Задача состоит в разделении ирисов на группы в зависимости от показателей(sepal length (cm), sepal width (cm))


sepal_length	sepal_width
0	5.1	3.5
1	4.9	3.0
2	4.7	3.2
3	4.6	3.1
4	5.0	3.6
...	...	...
145	6.7	3.0
146	6.3	2.5
147	6.5	3.0
148	6.2	3.4
149	5.9	3.0
150 rows × 2 columns

В нашем примере наблюдения визуально сгруппированы на 4 группы. Тем не менее, рассмотрим метод для определения наилучшего количества кластеров.

Определение оптимального количества кластеров для метода локтя

Как видно на следующем выше графике, локоть расположен в k = 4, что свидетельствует о том, что k = 4 является хорошим выбором для этого набора данных
Bизуальный анализ говорит о наличии 3 различных групп. Сделаем и такое построение:
Теперь видим, что каждая группа точек покрашена в цвет соответствующего кластера, а центроиды расположены внутри множества точек. Тем не менее, попробуем оценить качество кластеризации в обоих вариантах.


Количественная оценка качества кластеризации
Задача оценки качества кластеризации является более сложной по сравнению с оценкой качества классификации. Во-первых, такие оценки не должны зависеть от самих значений меток, а только от самого разбиения выборки. Во-вторых, не всегда известны истинные метки объектов, поэтому также нужны оценки, позволяющие оценить качество кластеризации, используя только неразмеченную выборку.

Выделяют внешние и внутренние метрики качества. Внешние используют информацию об истинном разбиении на кластеры, в то время как внутренние метрики не используют никакой внешней информации и оценивают качество кластеризации, основываясь только на наборе данных. Оптимальное число кластеров обычно определяют с использованием внутренних метрик.

Средний коэффициент силуэта --  0.4450525692083638
Средний коэффициент силуэта весьма близок к 0.5 , что говорит о относительным качестве кластеризации. Если силуэты зрительно значительно отличаются друг от друга по длине, то это является признаком субоптимальной кластеризации. Как правило, в этом случае центроиды кластеров стоят отдельно от множества точек кластера. Посчитаем средний силуэтный коэффициент для кластеризации k=4.
Средний коэффициент силуэта --  0.4248889536419922
Его значение немного ниже, чем в предыдущем случае. Формально k=3 - более оптимальное разбиение.


Сравнение результатов на обучающей и тестовой выборке
Посмотрим, как прогнозировать новых наблюдений принадлежность к кластерам, построенным по обучающим данным. Сравним значения средних силуэтных коэффициентов.

В обучающей выборке - 80% исходных наблюдений.
Добавляем к выборке дополнительный показатель.

sepal_length	sepal_width	petal_length
0	5.1	3.5	1.4
1	4.9	3.0	1.4
2	4.7	3.2	1.3
3	4.6	3.1	1.5
4	5.0	3.6	1.4
...	...	...	...
145	6.7	3.0	5.2
146	6.3	2.5	5.0
147	6.5	3.0	5.2
148	6.2	3.4	5.4
149	5.9	3.0	5.1
150 rows × 3 columns

Как видно на следующем выше графике, заметных изменений не обнаружилось.

Обучаем алгоритм и считаем средний силуэтный коэффициент.
Средний коэффициент силуэта --  0.5426144380745519
Средний коэффициент силуэта --  0.5862478392183824
Применяем модель к новым данным. Значение среднего силуэтного коэффициента незначительно ухудшилось.

Статистический анализ получившихся кластеров
Визуально кластеры немного отличаются друг от друга. Судя по графикам плотности, по показателю petal_length имеют различия, а по sepal_length и sepal_width имеют некоторые сходства. По диаграммам разброса видно, что оба кластера образуют не совсем плотное множество точек, разбиение нестрогое.

Accuracy: 0.23333333333333334
Из оценки кластеризации следует, что алгоритм (при разбиении на 3 кластера) достиг не высокой точности в своей работе

Accuracy: 0.88
Из оценки кластеризации следует, что алгоритм (при разбиении на 3 кластера) достиг высокой точности в своей работе, указывая правильную категоризацию большинства объектов данных.